# -*- coding: utf-8 -*-
"""googlenews_trend.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13iN1AjWOkQ06OGCjDmM9CsO-VZS7Qt_e
"""

!pip install google-api-python-client
!pip install google-search-results feedparser textblob nltk pandas matplotlib
import pandas as pd
from serpapi import GoogleSearch

# 검색 키워드 정의 (카테고리 : 쿼리)
KEYWORDS_QUERIES = {
    '체중 감량': '"probiotics" AND "weight loss"',
    '맛 관련': '"probiotics" AND "taste"',
    '부작용 관련': '"probiotics" AND "side effects"'
}

def get_google_news(query, num_results=10):
    """
    SerpApi를 사용하여 구글 뉴스 검색 결과 가져오기
    """
    api_key = "dd54908c763fe32aedb14e5b242a075b7c34b1eb0910452ee68baeeacf6c3b6c"

    params = {
        "engine": "google_news",
        "q": query,
        "hl": "en",   # 언어
        "num": num_results,
        "api_key": api_key
    }

    try:
        search = GoogleSearch(params)
        results = search.get_dict()
    except Exception as e:
        print(f"SerpApi 호출 오류: {e}")
        return []

    articles = []
    for news in results.get("news_results", []):
        articles.append({
            "title": news.get("title"),
            "link": news.get("link"),
            "snippet": news.get("snippet"),
            "date": news.get("date")
        })
    return articles

def search_and_export_csv(queries, filename="news_sample.csv"):
    """
    정의된 쿼리별 뉴스 검색 후 CSV 저장
    """
    all_rows = []
    trend_id = 1
    processed_links = set()

    for category, query_string in queries.items():
        print(f"--- 검색 시작: {category} ({query_string}) ---")
        new_articles = get_google_news(query_string, num_results=5)

        for article in new_articles:
            link = article["link"]

            if link not in processed_links:
                # CSV 요구 포맷에 맞게 변환
                row = {
                    "trend_id": trend_id,
                    "date": article.get("date", ""),
                    "platform": "news",
                    "keyword": query_string,
                    "post_text": article.get("title", "") + " | " + (article.get("snippet") or ""),
                    "hashtags": f"#probiotics #{category.replace(' ', '')}"
                }
                all_rows.append(row)
                processed_links.add(link)
                trend_id += 1

    # DataFrame → CSV 저장
    df = pd.DataFrame(all_rows, columns=["trend_id","date","platform","keyword","post_text","hashtags"])
    df.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"CSV 저장 완료: {filename}")

if __name__ == "__main__":
    search_and_export_csv(KEYWORDS_QUERIES)